{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeHNpZgwCuzO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import RFECV, SelectFromModel, SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "5CaWusr4mjBN",
        "outputId": "6c2e90bb-82ba-46da-d830-50ca2235c855"
      },
      "outputs": [],
      "source": [
        "#Reading the dataset using \"read_csv\" a prebuild function in the \"pandas\" package, the \"index_col\" contains the column to use as the row labels of the DataFrame\n",
        "Stock = pd.read_csv('AppleDataset.csv',  index_col=0)\n",
        "df_Stock = Stock\n",
        "#\"rename\" prebuild function that enables us to change the name of a column in a Dataframe\n",
        "df_Stock = df_Stock.rename(columns={'Close(t)':'Close'})\n",
        "#Display using Head function that returns the dataframe or series with the first few rows (by default 5)\n",
        "df_Stock.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "4f6dCiC2sE0y",
        "outputId": "87b6dbd4-cc06-4bf4-f4ba-f01e5f20ec06"
      },
      "outputs": [],
      "source": [
        "#Converting columns that contain data type (Dtype) =object to float using the \"astype\" prebuild function \n",
        "#In the same time replacing \"$\" symbol with an empty space \n",
        "df_Stock[\"Close\"] = df_Stock[' Close/Last'].str.replace('$','').astype(float)\n",
        "df_Stock['Open'] = df_Stock[' Open'].str.replace('$','').astype(float)\n",
        "df_Stock['High'] = df_Stock[' High'].str.replace('$','').astype(float)\n",
        "df_Stock['Low'] = df_Stock[' Low'].str.replace('$','').astype(float)\n",
        "\n",
        "df_Stock['Volume'] = df_Stock[' Volume']\n",
        "#With the new named columns containing the converted datatypes, we are droping pevious columns\n",
        "drop = [' Close/Last',' Open',' High',' Low',' Volume']\n",
        "df_Stock = df_Stock.drop(drop,axis=1)\n",
        "#Diplaying the new dataset \n",
        "df_Stock.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVV3jZwocsU"
      },
      "outputs": [],
      "source": [
        "def create_train_test_set(df_Stock):\n",
        "    #Taking all features as predictors of course droping the close  column...\n",
        "    \"\"\"\n",
        "    the close  column represents the predicted value of close prices in the \n",
        "    previous 10 years. so not to make our model overfit and the learning to be biased by these values \n",
        "    we drop this column.\n",
        "\n",
        "    \"\"\"\n",
        "    features = df_Stock.drop(columns=['Close'], axis=1)\n",
        "\n",
        "    #now the target is to predit the values of the close column which represents the predicted \n",
        "    #prices by which shares of apple corporation will be sold (or bought).\n",
        "    target = df_Stock['Close']\n",
        "    \n",
        "\n",
        "    data_len = df_Stock.shape[0]\n",
        "    print('Historical Stock Data length is - ', str(data_len))\n",
        "\n",
        "    #create a chronological split for train and testing\n",
        "    train_split = int(data_len * 0.7)\n",
        "    print('Training Set length - ', str(train_split))\n",
        "\n",
        "    val_split = train_split + int(data_len * 0.2)\n",
        "    print('Validation Set length - ', str(int(data_len * 0.2)))\n",
        "\n",
        "    print('Test Set length - ', str(int(data_len * 0.1)))\n",
        "\n",
        "    # Splitting features and target into train, validation and test samples \n",
        "    X_train, X_val, X_test = features[:train_split], features[train_split:val_split], features[val_split:]\n",
        "    Y_train, Y_val, Y_test = target[:train_split], target[train_split:val_split], target[val_split:]\n",
        "\n",
        "    #print shape of samples\n",
        "    print(X_train.shape, X_val.shape, X_test.shape)\n",
        "    print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "    \n",
        "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YnJ8iJCooX-",
        "outputId": "db20cf53-e9fc-444e-84ac-ad1819760716"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = create_train_test_set(df_Stock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFKtVmqhsblS",
        "outputId": "3ccb8d68-e773-4539-e4bc-fcfd550efa74"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Load stock price data\n",
        "stock_prices = df_Stock\n",
        "\n",
        "# Define window size and step size\n",
        "window_size = 30\n",
        "step_size = 7\n",
        "\n",
        "# Initialize model\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Iterate over time periods\n",
        "mse_scores = []\n",
        "for i in range(window_size, len(stock_prices), step_size):\n",
        "    # Split data into training and test sets\n",
        "    X_train = stock_prices.iloc[i-window_size:i, 1:].values\n",
        "    y_train = stock_prices.iloc[i-window_size:i, 0].values\n",
        "    X_test = stock_prices.iloc[i:i+step_size, 1:].values\n",
        "    y_test = stock_prices.iloc[i:i+step_size, 0].values\n",
        "\n",
        "    # Fit model on training data\n",
        "    lr.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on test data\n",
        "    y_pred = lr.predict(X_test)\n",
        "\n",
        "    # Calculate mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "# Calculate average mean squared error\n",
        "avg_mse = sum(mse_scores) / len(mse_scores)\n",
        "print(\"Average MSE: \", avg_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug5krl00oqaF",
        "outputId": "5d4f08b5-a90a-4a62-b217-119f19bfe967"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression #uploading the linear regression model \n",
        "\n",
        "lr = LinearRegression()\n",
        "#fit() is implemented by every estimator and it accepts an input for the sample data ( X_train ) and for supervised models it also accepts an argument for labels (Y_train)\n",
        "lr.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT4VcEeyo0Js",
        "outputId": "d9aef241-f79a-4f50-8ae0-0b2746f2e069"
      },
      "outputs": [],
      "source": [
        "#Displaying the models coefficients and intercept \n",
        "print('LR Coefficients: \\n', lr.coef_)\n",
        "print('LR Intercept: \\n', lr.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uVatBQwo4bc",
        "outputId": "df5682fa-af62-4e42-df11-4b0a1b80e2fd"
      },
      "outputs": [],
      "source": [
        "print(\"Performance (R^2): \", lr.score(X_train, Y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loJ0XiBlpAPE"
      },
      "outputs": [],
      "source": [
        "#Calculating the regression error in order to be used while evaluating the model's performance\n",
        "def get_mape(y_true, y_pred): \n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SaDOHxT9_2P"
      },
      "source": [
        "5.1. Training the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INMrGqSUpBtd"
      },
      "outputs": [],
      "source": [
        "#In this case we are using linear regression \n",
        "\n",
        "Y_train_pred = lr.predict(X_train)\n",
        "Y_val_pred = lr.predict(X_val)\n",
        "Y_test_pred = lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEtw1LdIpFZF",
        "outputId": "85206252-ad81-4f7f-a0f9-7f890821e6fe"
      },
      "outputs": [],
      "source": [
        "#Using different metrics (prebuild function of sklearn) to evaluate the model's performance\n",
        "print(\"let's get metrics for training ...........\\n\\n\")\n",
        "\n",
        "print(\"Training R-squared: \",round(metrics.r2_score(Y_train,Y_train_pred),2))\n",
        "print(\"Training Explained Variation: \",round(metrics.explained_variance_score(Y_train,Y_train_pred),2))\n",
        "print('Training MAPE:', round(get_mape(Y_train,Y_train_pred), 2)) \n",
        "print('Training Mean Squared Error:', round(metrics.mean_squared_error(Y_train,Y_train_pred), 2)) \n",
        "print(\"Training RMSE: \",round(np.sqrt(metrics.mean_squared_error(Y_train,Y_train_pred)),2))\n",
        "print(\"Training MAE: \",round(metrics.mean_absolute_error(Y_train,Y_train_pred),2))\n",
        "\n",
        "print(\"\\n\\nNow it is time for validation ...........\\n\\n\")\n",
        "\n",
        "print(\"Validation R-squared: \",round(metrics.r2_score(Y_val,Y_val_pred),2))\n",
        "print(\"Validation Explained Variation: \",round(metrics.explained_variance_score(Y_val,Y_val_pred),2))\n",
        "print('Validation MAPE:', round(get_mape(Y_val,Y_val_pred), 2)) \n",
        "print('Validation Mean Squared Error:', round(metrics.mean_squared_error(Y_train,Y_train_pred), 2)) \n",
        "print(\"Validation RMSE: \",round(np.sqrt(metrics.mean_squared_error(Y_val,Y_val_pred)),2))\n",
        "print(\"Validation MAE: \",round(metrics.mean_absolute_error(Y_val,Y_val_pred),2))\n",
        "\n",
        "\n",
        "print(\"\\n\\nlet's go directly and dicover how our model did for the testing dataset ...\\n\\n\")\n",
        "\n",
        "\n",
        "print(\"Test R-squared: \",round(metrics.r2_score(Y_test,Y_test_pred),2))\n",
        "print(\"Test Explained Variation: \",round(metrics.explained_variance_score(Y_test,Y_test_pred),2))\n",
        "print('Test MAPE:', round(get_mape(Y_test,Y_test_pred), 2)) \n",
        "print('Test Mean Squared Error:', round(metrics.mean_squared_error(Y_test,Y_test_pred), 2)) \n",
        "print(\"Test RMSE: \",round(np.sqrt(metrics.mean_squared_error(Y_test,Y_test_pred)),2))\n",
        "print(\"Test MAE: \",round(metrics.mean_absolute_error(Y_test,Y_test_pred),2))\n",
        "\n",
        "print(\"\\nIt seems WE DID WELL \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qVJmqXKIpy-c",
        "outputId": "96c7d0a7-a61d-4935-91e4-479f8b06639a"
      },
      "outputs": [],
      "source": [
        "#Displaying the values of actual price at a closing trading day and the predicted value of the price \n",
        "df_pred = pd.DataFrame(Y_val.values, columns=['close Actual'], index=Y_val.index)\n",
        "df_pred['Close Predicted'] = Y_val_pred\n",
        "df_pred = df_pred.reset_index()\n",
        "df_pred\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6615b6879737564f1f02f43333aea4fd407b62a7dadee27399a07c947536a477"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
