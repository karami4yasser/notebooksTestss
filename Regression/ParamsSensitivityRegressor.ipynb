{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeHNpZgwCuzO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import RFECV, SelectFromModel, SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "5CaWusr4mjBN",
        "outputId": "4a3c1700-8708-4eb6-e699-fe69266a3914"
      },
      "outputs": [],
      "source": [
        "#Reading the dataset using \"read_csv\" a prebuild function in the \"pandas\" package, the \"index_col\" contains the column to use as the row labels of the DataFrame\n",
        "Stock = pd.read_csv('AppleDataset.csv',  index_col=0)\n",
        "df_Stock = Stock\n",
        "#\"rename\" prebuild function that enables us to change the name of a column in a Dataframe\n",
        "df_Stock = df_Stock.rename(columns={'Close(t)':'Close'})\n",
        "#Display using Head function that returns the dataframe or series with the first few rows (by default 5)\n",
        "df_Stock.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "4f6dCiC2sE0y",
        "outputId": "8d57c624-6299-4c47-fc56-fa46b3a21e64"
      },
      "outputs": [],
      "source": [
        "#Converting columns that contain data type (Dtype) =object to float using the \"astype\" prebuild function \n",
        "#In the same time replacing \"$\" symbol with an empty space \n",
        "df_Stock[\"Close\"] = df_Stock[' Close/Last'].str.replace('$','').astype(float)\n",
        "df_Stock['Open'] = df_Stock[' Open'].str.replace('$','').astype(float)\n",
        "df_Stock['High'] = df_Stock[' High'].str.replace('$','').astype(float)\n",
        "df_Stock['Low'] = df_Stock[' Low'].str.replace('$','').astype(float)\n",
        "\n",
        "df_Stock['Volume'] = df_Stock[' Volume']\n",
        "#With the new named columns containing the converted datatypes, we are droping pevious columns\n",
        "drop = [' Close/Last',' Open',' High',' Low',' Volume']\n",
        "df_Stock = df_Stock.drop(drop,axis=1)\n",
        "#Diplaying the new dataset \n",
        "df_Stock.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVV3jZwocsU"
      },
      "outputs": [],
      "source": [
        "def create_train_test_set(df_Stock):\n",
        "    #Taking all features as predictors of course droping the close  column...\n",
        "    \"\"\"\n",
        "    the close  column represents the predicted value of close prices in the \n",
        "    previous 10 years. so not to make our model overfit and the learning to be biased by these values \n",
        "    we drop this column.\n",
        "\n",
        "    \"\"\"\n",
        "    features = df_Stock.drop(columns=['Close'], axis=1)\n",
        "\n",
        "    #now the target is to predit the values of the close column which represents the predicted \n",
        "    #prices by which shares of apple corporation will be sold (or bought).\n",
        "    target = df_Stock['Close']\n",
        "    \n",
        "\n",
        "    data_len = df_Stock.shape[0]\n",
        "    print('Historical Stock Data length is - ', str(data_len))\n",
        "\n",
        "    #create a chronological split for train and testing\n",
        "    train_split = int(data_len * 0.7)\n",
        "    print('Training Set length - ', str(train_split))\n",
        "\n",
        "    val_split = train_split + int(data_len * 0.2)\n",
        "    print('Validation Set length - ', str(int(data_len * 0.2)))\n",
        "\n",
        "    print('Test Set length - ', str(int(data_len * 0.1)))\n",
        "\n",
        "    # Splitting features and target into train, validation and test samples \n",
        "    X_train, X_val, X_test = features[:train_split], features[train_split:val_split], features[val_split:]\n",
        "    Y_train, Y_val, Y_test = target[:train_split], target[train_split:val_split], target[val_split:]\n",
        "\n",
        "    #print shape of samples\n",
        "    print(X_train.shape, X_val.shape, X_test.shape)\n",
        "    print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "    \n",
        "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YnJ8iJCooX-",
        "outputId": "4b672bc8-57d7-4f0b-f8d4-ae06b9e3a490"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = create_train_test_set(df_Stock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqnc4KiCmhLh",
        "outputId": "059ad2e5-62b2-4fda-c07b-cb1a5d7bc9a5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso #uploading the linear regression model \n",
        "\n",
        "# define the range of parameter values to test\n",
        "param_grid = {\n",
        "    'normalize': [True, False],\n",
        "    'fit_intercept': [True, False],\n",
        "    \n",
        "   \n",
        "}\n",
        "# Param grid for Ridge regression\n",
        "param_grid_ridge = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'fit_intercept': [True, False],\n",
        "    'normalize': [True, False],\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
        "    'max_iter': [None, 1000, 5000, 10000],\n",
        "    'tol': [0.001, 0.0001, 0.00001],\n",
        "}\n",
        "\n",
        "# Param grid for Lasso regression\n",
        "param_grid_lasso = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'fit_intercept': [True, False],\n",
        "    'normalize': [True, False],\n",
        "    'precompute': [True, False],\n",
        "    'copy_X': [True, False],\n",
        "    'max_iter': [None, 1000, 5000, 10000],\n",
        "    'tol': [0.001, 0.0001, 0.00001],\n",
        "    'warm_start': [True, False],\n",
        "    'positive': [True, False],\n",
        "    'selection': ['cyclic', 'random'],\n",
        "}\n",
        "# perform 10-fold cross-validation\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# perform grid search to find the best parameter values\n",
        "grid_searchlr = GridSearchCV(LinearRegression(), param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
        "grid_searchRidge = GridSearchCV(Ridge(), param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
        "grid_searchLasso = GridSearchCV(Lasso(), param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
        "\n",
        "grid_searchlr.fit(X_train, Y_train)\n",
        "grid_searchRidge.fit(X_train, Y_train)\n",
        "grid_searchLasso.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug5krl00oqaF",
        "outputId": "a007d588-f778-4319-9ede-9510d36e5c12"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression #uploading the linear regression model \n",
        "\n",
        "lr = LinearRegression()\n",
        "#fit() is implemented by every estimator and it accepts an input for the sample data ( X_train ) and for supervised models it also accepts an argument for labels (Y_train)\n",
        "lr.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loJ0XiBlpAPE"
      },
      "outputs": [],
      "source": [
        "#Calculating the regression error in order to be used while evaluating the model's performance\n",
        "def get_mape(y_true, y_pred): \n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INMrGqSUpBtd"
      },
      "outputs": [],
      "source": [
        "#In this case we are using linear regression \n",
        "\n",
        "Y_train_pred = lr.predict(X_train)\n",
        "Y_val_pred = lr.predict(X_val)\n",
        "Y_test_pred = lr.predict(X_test)\n",
        "Y_BestParm_Val_pred=grid_searchlr.predict(X_val)\n",
        "Y_RidgeBest_Val_pred=grid_searchlr.predict(X_val)\n",
        "Y_LassoBest_Val_pred=grid_searchlr.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z2xj1_nRy7A",
        "outputId": "bdce26f4-58fe-49b2-ced0-32a538a5a868"
      },
      "outputs": [],
      "source": [
        "print(\"The Score with The Use Of FineTuning\",metrics.r2_score(Y_val,Y_BestParm_Val_pred))\n",
        "print(\"The Score without Fintuning\",metrics.r2_score(Y_val,Y_val_pred))\n",
        "print('Validation Mean Squared Error for The Normale LinearRegressor :', round(metrics.mean_squared_error(Y_val,Y_val_pred), 2)) \n",
        "print('Validation Mean Squared Error for The  LinearRegressor With Hyperparameter FineTuning :', round(metrics.mean_squared_error(Y_val,Y_BestParm_Val_pred), 2)) \n",
        "print('Validation Mean Squared Error for The The  LinearRegressor With L2  :', round(metrics.mean_squared_error(Y_val,Y_RidgeBest_Val_pred), 2)) \n",
        "print('Validation Mean Squared Error for The The  LinearRegressor With L1  :', round(metrics.mean_squared_error(Y_val,Y_LassoBest_Val_pred), 2)) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qVJmqXKIpy-c",
        "outputId": "4333dd67-647c-4c4d-8c41-9103e9bed772"
      },
      "outputs": [],
      "source": [
        "#Displaying the values of actual price at a closing trading day and the predicted value of the price \n",
        "df_pred = pd.DataFrame(Y_val.values, columns=['close Actual'], index=Y_val.index)\n",
        "df_pred['Close Predicted'] = Y_val_pred\n",
        "df_pred['Close Predicted_Hypreparameters']=Y_BestParm_Val_pred\n",
        "df_pred['Close Predicted_Ridge_Hypreparameters']=Y_RidgeBest_Val_pred\n",
        "df_pred['Close Predicted_Lasso_Hypreparameters']=Y_LassoBest_Val_pred\n",
        "\n",
        "df_pred = df_pred.reset_index()\n",
        "df_pred\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6615b6879737564f1f02f43333aea4fd407b62a7dadee27399a07c947536a477"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
