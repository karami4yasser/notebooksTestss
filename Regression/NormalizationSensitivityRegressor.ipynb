{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeHNpZgwCuzO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import RFECV, SelectFromModel, SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "5CaWusr4mjBN",
        "outputId": "764214ed-acb7-4423-d1e8-0ab3ec6938c9"
      },
      "outputs": [],
      "source": [
        "#Reading the dataset using \"read_csv\" a prebuild function in the \"pandas\" package, the \"index_col\" contains the column to use as the row labels of the DataFrame\n",
        "Stock = pd.read_csv('AppleDataset.csv',  index_col=0)\n",
        "df_Stock = Stock\n",
        "#\"rename\" prebuild function that enables us to change the name of a column in a Dataframe\n",
        "df_Stock = df_Stock.rename(columns={'Close(t)':'Close'})\n",
        "#Display using Head function that returns the dataframe or series with the first few rows (by default 5)\n",
        "df_Stock.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "4f6dCiC2sE0y",
        "outputId": "23ee9e9d-ba09-44d4-bbfd-d5f617edfbd6"
      },
      "outputs": [],
      "source": [
        "#Converting columns that contain data type (Dtype) =object to float using the \"astype\" prebuild function \n",
        "#In the same time replacing \"$\" symbol with an empty space \n",
        "df_Stock[\"Close\"] = df_Stock[' Close/Last'].str.replace('$','').astype(float)\n",
        "df_Stock['Open'] = df_Stock[' Open'].str.replace('$','').astype(float)\n",
        "df_Stock['High'] = df_Stock[' High'].str.replace('$','').astype(float)\n",
        "df_Stock['Low'] = df_Stock[' Low'].str.replace('$','').astype(float)\n",
        "\n",
        "df_Stock['Volume'] = df_Stock[' Volume']\n",
        "#With the new named columns containing the converted datatypes, we are droping pevious columns\n",
        "drop = [' Close/Last',' Open',' High',' Low',' Volume']\n",
        "df_Stock = df_Stock.drop(drop,axis=1)\n",
        "#Diplaying the new dataset \n",
        "df_Stock.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVV3jZwocsU"
      },
      "outputs": [],
      "source": [
        "def create_train_test_set(df_Stock):\n",
        "    #Taking all features as predictors of course droping the close  column...\n",
        "    \"\"\"\n",
        "    the close  column represents the predicted value of close prices in the \n",
        "    previous 10 years. so not to make our model overfit and the learning to be biased by these values \n",
        "    we drop this column.\n",
        "\n",
        "    \"\"\"\n",
        "    features = df_Stock.drop(columns=['Close'], axis=1)\n",
        "\n",
        "    #now the target is to predit the values of the close column which represents the predicted \n",
        "    #prices by which shares of apple corporation will be sold (or bought).\n",
        "    target = df_Stock['Close']\n",
        "    \n",
        "\n",
        "    data_len = df_Stock.shape[0]\n",
        "    print('Historical Stock Data length is - ', str(data_len))\n",
        "\n",
        "    #create a chronological split for train and testing\n",
        "    train_split = int(data_len * 0.7)\n",
        "    print('Training Set length - ', str(train_split))\n",
        "\n",
        "    val_split = train_split + int(data_len * 0.2)\n",
        "    print('Validation Set length - ', str(int(data_len * 0.2)))\n",
        "\n",
        "    print('Test Set length - ', str(int(data_len * 0.1)))\n",
        "\n",
        "    # Splitting features and target into train, validation and test samples \n",
        "    X_train, X_val, X_test = features[:train_split], features[train_split:val_split], features[val_split:]\n",
        "    Y_train, Y_val, Y_test = target[:train_split], target[train_split:val_split], target[val_split:]\n",
        "\n",
        "    #print shape of samples\n",
        "    print(X_train.shape, X_val.shape, X_test.shape)\n",
        "    print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "    \n",
        "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YnJ8iJCooX-",
        "outputId": "f451b3a0-a596-4714-dedd-2b61157bf4c0"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = create_train_test_set(df_Stock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqnc4KiCmhLh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.linear_model import LinearRegression #uploading the linear regression model \n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler,PowerTransformer, QuantileTransformer, Normalizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# define a list of normalization techniques to test\n",
        "\n",
        "normalizers = [\n",
        "    ('StandardScaler', StandardScaler()),\n",
        "    ('MinMaxScaler', MinMaxScaler()),\n",
        "    ('RobustScaler', RobustScaler()),\n",
        "    ('PowerTransformer', PowerTransformer()),\n",
        "    ('QuantileTransformer', QuantileTransformer()),\n",
        "    ('Normalizer', Normalizer())\n",
        "]\n",
        "# # create a pipeline that applies each normalization technique and the linear regression model\n",
        "# pipeline = Pipeline(normalizers + [('LinearRegression', LinearRegression())])\n",
        "\n",
        "# # evaluate the performance of the pipeline using cross-validation\n",
        "# cv_scores = cross_val_score(pipeline, X_train, Y_train, cv=10, scoring='neg_mean_squared_error')\n",
        "\n",
        "# # compute the mean and standard deviation of the cross-validation scores\n",
        "# mean_score = np.mean(-cv_scores)\n",
        "# std_score = np.std(-cv_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3w9f3oJbUS",
        "outputId": "d2d32ca6-f7eb-469b-abf6-19093b6e6597"
      },
      "outputs": [],
      "source": [
        "# Create pipelines for each normalization technique\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipelines = []\n",
        "for name, normalizer in normalizers:\n",
        "    pipeline = make_pipeline(normalizer, LinearRegression())\n",
        "    pipelines.append((name, pipeline))\n",
        "\n",
        "# Train and test each pipeline\n",
        "for name, pipeline in pipelines:\n",
        "    pipeline.fit(X_train, Y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    r2 = metrics.r2_score(Y_test, y_pred)\n",
        "    Y_val_pred = pipeline.predict(X_val)\n",
        "    print(f'{name}: R2 score = {r2:.3f}')\n",
        "    print('Validation Mean Squared Error for :',name, round(metrics.mean_squared_error(Y_val,Y_val_pred), 2)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLmXYxK1m9az",
        "outputId": "23df5333-fbbc-4e9a-aa32-625d1516e577"
      },
      "outputs": [],
      "source": [
        "# # print the results\n",
        "# print('Mean score:', cv_scores)\n",
        "\n",
        "# print('Mean score:', mean_score)\n",
        "# print('Standard deviation:', std_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loJ0XiBlpAPE"
      },
      "outputs": [],
      "source": [
        "#Calculating the regression error in order to be used while evaluating the model's performance\n",
        "def get_mape(y_true, y_pred): \n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "qVJmqXKIpy-c",
        "outputId": "33382246-5082-4ae0-bff6-06d8f38e879c"
      },
      "outputs": [],
      "source": [
        "#Displaying the values of actual price at a closing trading day and the predicted value of the price\n",
        "# Train and test each pipeline\n",
        "df_pred = pd.DataFrame(Y_val.values, columns=['close Actual'], index=Y_val.index)\n",
        "for name, pipeline in pipelines:\n",
        "    y_pred = pipeline.predict(X_val)\n",
        "    df_pred['Close Predicted'+\"_\"+name] = y_pred \n",
        "df_pred = df_pred.reset_index()\n",
        "df_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZQ4fy2BM90t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6615b6879737564f1f02f43333aea4fd407b62a7dadee27399a07c947536a477"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
